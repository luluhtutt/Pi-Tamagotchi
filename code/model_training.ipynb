{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4323c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088b24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'fer2013.csv'\n",
    "image_size = (48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3abde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(FILE_PATH)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d30af2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c64e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = data['pixels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a083d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a441cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and emotions \n",
    "faces = []\n",
    "\n",
    "for p in pixels:\n",
    "    face = [int(pix) for pix in p.split(' ')]\n",
    "    face = np.asarray(face).reshape(width, height)\n",
    "    face = cv2.resize(face.astype('uint8'), image_size)\n",
    "    faces.append(face.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2117356",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2eea864",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.asarray(faces)\n",
    "faces = np.expand_dims(faces, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78827d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = pd.get_dummies(data['emotion']).values\n",
    "emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5de3eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the images \n",
    "def preprocess(x, v2=True):  # v2 to keep the image btw. -1 and 1\n",
    "    x = x.astype('float32')\n",
    "    x = x/255.0\n",
    "    if v2:\n",
    "        x = (x - 0.5)*2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ccd95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = preprocess(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132099e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('showing some sample training images')\n",
    "# for image in np.arange(0,10):\n",
    "#     cv2.namedWindow('some sample training images', cv2.WINDOW_NORMAL)\n",
    "#     cv2.imshow('some sample training images',faces[image])\n",
    "#     cv2.waitKey(500)\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a77064",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7074e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22516006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35880bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Convolution2D, Conv2D, Dropout, AveragePooling2D, BatchNormalization, GlobalAveragePooling2D, Flatten, Input, MaxPooling2D, SeparableConv2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03a9974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6974bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import DepthwiseConv2D, BatchNormalization, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558859d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7e0801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "image_shape = (48, 48, 1)\n",
    "verbose = True \n",
    "num_class = 7\n",
    "patience = 50  # number of epochs with no improvement after which training will be stopped\n",
    "base_path = 'models/'\n",
    "l2_regularization = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8c25a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb6f50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization = l2(l2_regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bb94826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "image_input = Input(image_shape)\n",
    "x = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), kernel_regularizer=regularization, use_bias=False)(image_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# module 1\n",
    "# residual module \n",
    "residual = Conv2D(filters=16, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "# x = SeparableConv2D(filters=16, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = SeparableConv2D(filters=16, kernel_size=(3,3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = SeparableConv2D(filters=16, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = SeparableConv2D(filters=16, kernel_size=(3,3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "x = layers.add([x,residual])\n",
    "\n",
    "# module 2\n",
    "# residual module \n",
    "residual = Conv2D(filters=32, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "# x = SeparableConv2D(filters=32, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3,3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = SeparableConv2D(filters=32, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3,3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "x = layers.add([x,residual])\n",
    "\n",
    "# module 3\n",
    "# residual module \n",
    "residual = Conv2D(filters=64, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "# x = SeparableConv2D(filters=64, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3,3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = SeparableConv2D(filters=64, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3,3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "x = layers.add([x,residual])\n",
    "\n",
    "# module 4\n",
    "# residual module \n",
    "residual = Conv2D(filters=128, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "# x = SeparableConv2D(filters=128, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3,3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# x = SeparableConv2D(filters=128, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3,3), padding='same', depthwise_regularizer=regularization, pointwise_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "x = layers.add([x,residual])\n",
    "\n",
    "x = Conv2D(filters=num_class, kernel_size=(3,3), padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "output = Activation('softmax', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "549e9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(image_input, output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "676c65c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks \n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "\n",
    "# trained_models_path = base_path + '_mini_xception'\n",
    "# model_names = trained_models_path + '.{epoch:02d}_{val_acc:.2f}.hdf5'\n",
    "# model_checkpoint = ModelCheckpoint(filepath=model_names, monitor='val_loss', verbose=verbose, save_best_only=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('mini_xception.keras', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('mini_xception_training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cc89869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m  3/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 47ms/step - accuracy: 0.2396 - loss: 6.4146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sana/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 68ms/step - accuracy: 0.2833 - loss: 4.1082 - val_accuracy: 0.4094 - val_loss: 1.9311 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 73ms/step - accuracy: 0.3125 - loss: 2.2676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sana/anaconda3/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_acc available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n",
      "2024-05-09 13:48:24.500031: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/sana/anaconda3/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3125 - loss: 1.1351 - val_accuracy: 0.4106 - val_loss: 1.9274 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 72ms/step - accuracy: 0.4094 - loss: 1.8246 - val_accuracy: 0.4817 - val_loss: 1.5605 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 81ms/step - accuracy: 0.3438 - loss: 1.7028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 13:49:33.179985: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3438 - loss: 0.8523 - val_accuracy: 0.4833 - val_loss: 1.5540 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 70ms/step - accuracy: 0.4515 - loss: 1.6089 - val_accuracy: 0.4313 - val_loss: 1.6562 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 73ms/step - accuracy: 0.4688 - loss: 1.5027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 13:50:39.660613: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.7522 - val_accuracy: 0.4347 - val_loss: 1.6440 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m874s\u001b[0m 975ms/step - accuracy: 0.4772 - loss: 1.5163 - val_accuracy: 0.4363 - val_loss: 1.6597 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 69ms/step - accuracy: 0.2500 - loss: 1.8661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:05:17.014046: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2500 - loss: 0.9341 - val_accuracy: 0.4365 - val_loss: 1.6482 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.4882 - loss: 1.4752 - val_accuracy: 0.4955 - val_loss: 1.4544 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06\u001b[0m 74ms/step - accuracy: 0.4688 - loss: 1.5605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:06:21.298624: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.7811 - val_accuracy: 0.4872 - val_loss: 1.4705 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 64ms/step - accuracy: 0.5036 - loss: 1.4326 - val_accuracy: 0.4482 - val_loss: 1.6077 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 63ms/step - accuracy: 0.6250 - loss: 1.1496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:07:22.685079: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 0.5755 - val_accuracy: 0.4586 - val_loss: 1.5685 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 66ms/step - accuracy: 0.5115 - loss: 1.4040 - val_accuracy: 0.4452 - val_loss: 1.5884 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 63ms/step - accuracy: 0.4688 - loss: 1.4332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:08:25.801511: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.7174 - val_accuracy: 0.4257 - val_loss: 1.6450 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 65ms/step - accuracy: 0.5127 - loss: 1.3936 - val_accuracy: 0.4714 - val_loss: 1.4558 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 62ms/step - accuracy: 0.4688 - loss: 1.5296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:09:27.786290: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4688 - loss: 0.7656 - val_accuracy: 0.4748 - val_loss: 1.4604 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 64ms/step - accuracy: 0.5125 - loss: 1.3818 - val_accuracy: 0.5178 - val_loss: 1.3771 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 66ms/step - accuracy: 0.4688 - loss: 1.2987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:10:28.657733: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.6501 - val_accuracy: 0.5098 - val_loss: 1.3998 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 69ms/step - accuracy: 0.5296 - loss: 1.3667 - val_accuracy: 0.5059 - val_loss: 1.3578 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 67ms/step - accuracy: 0.5312 - loss: 1.2175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:11:34.066405: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.6094 - val_accuracy: 0.5116 - val_loss: 1.3501 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.5257 - loss: 1.3582 - val_accuracy: 0.5118 - val_loss: 1.3348 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 78ms/step - accuracy: 0.4688 - loss: 1.3154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:12:37.305158: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.6584 - val_accuracy: 0.5120 - val_loss: 1.3385 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 66ms/step - accuracy: 0.5268 - loss: 1.3596 - val_accuracy: 0.5425 - val_loss: 1.3265 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 68ms/step - accuracy: 0.4375 - loss: 1.4586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:13:40.324647: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 0.7301 - val_accuracy: 0.5405 - val_loss: 1.3375 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.5305 - loss: 1.3525 - val_accuracy: 0.5538 - val_loss: 1.2818 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 64ms/step - accuracy: 0.4375 - loss: 1.5309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:14:43.898127: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4375 - loss: 0.7663 - val_accuracy: 0.5528 - val_loss: 1.2828 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 63ms/step - accuracy: 0.5372 - loss: 1.3368 - val_accuracy: 0.5343 - val_loss: 1.3509 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 57ms/step - accuracy: 0.6250 - loss: 1.2809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:15:43.308604: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 0.6412 - val_accuracy: 0.5393 - val_loss: 1.3369 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.5300 - loss: 1.3441 - val_accuracy: 0.5508 - val_loss: 1.2923 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 68ms/step - accuracy: 0.5000 - loss: 1.4330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:16:46.506824: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.7173 - val_accuracy: 0.5517 - val_loss: 1.2940 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 63ms/step - accuracy: 0.5292 - loss: 1.3369 - val_accuracy: 0.5426 - val_loss: 1.2973 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 81ms/step - accuracy: 0.5312 - loss: 1.2414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:17:46.723673: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.6214 - val_accuracy: 0.5380 - val_loss: 1.3086 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 66ms/step - accuracy: 0.5377 - loss: 1.3208 - val_accuracy: 0.4882 - val_loss: 1.4316 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 65ms/step - accuracy: 0.4375 - loss: 1.5508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:18:49.634997: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 0.7763 - val_accuracy: 0.4865 - val_loss: 1.4330 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.5351 - loss: 1.3291 - val_accuracy: 0.5111 - val_loss: 1.4070 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 1.4421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:19:53.326361: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.7218 - val_accuracy: 0.5194 - val_loss: 1.3811 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5386 - loss: 1.3257\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 72ms/step - accuracy: 0.5386 - loss: 1.3257 - val_accuracy: 0.5261 - val_loss: 1.3093 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 1.4655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:21:00.596440: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.7335 - val_accuracy: 0.5263 - val_loss: 1.3097 - learning_rate: 1.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 76ms/step - accuracy: 0.5584 - loss: 1.2707 - val_accuracy: 0.5840 - val_loss: 1.1859 - learning_rate: 1.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 71ms/step - accuracy: 0.5312 - loss: 1.3989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:22:12.544606: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.7002 - val_accuracy: 0.5843 - val_loss: 1.1862 - learning_rate: 1.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 69ms/step - accuracy: 0.5678 - loss: 1.2316 - val_accuracy: 0.5871 - val_loss: 1.1802 - learning_rate: 1.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 60ms/step - accuracy: 0.4688 - loss: 1.3653"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:23:17.727684: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4688 - loss: 0.6834 - val_accuracy: 0.5868 - val_loss: 1.1801 - learning_rate: 1.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 65ms/step - accuracy: 0.5855 - loss: 1.2040 - val_accuracy: 0.5826 - val_loss: 1.1733 - learning_rate: 1.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 69ms/step - accuracy: 0.6250 - loss: 1.1348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:24:18.841619: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 0.5680 - val_accuracy: 0.5823 - val_loss: 1.1738 - learning_rate: 1.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 66ms/step - accuracy: 0.5807 - loss: 1.2101 - val_accuracy: 0.5939 - val_loss: 1.1670 - learning_rate: 1.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 71ms/step - accuracy: 0.5938 - loss: 1.3047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:25:21.714181: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5938 - loss: 0.6531 - val_accuracy: 0.5933 - val_loss: 1.1673 - learning_rate: 1.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 64ms/step - accuracy: 0.5800 - loss: 1.1979 - val_accuracy: 0.5936 - val_loss: 1.1542 - learning_rate: 1.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 64ms/step - accuracy: 0.4375 - loss: 1.5243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:26:23.142074: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 0.7630 - val_accuracy: 0.5928 - val_loss: 1.1542 - learning_rate: 1.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 64ms/step - accuracy: 0.5777 - loss: 1.2036 - val_accuracy: 0.5929 - val_loss: 1.1618 - learning_rate: 1.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 65ms/step - accuracy: 0.6875 - loss: 1.1269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:27:23.816110: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.5641 - val_accuracy: 0.5924 - val_loss: 1.1614 - learning_rate: 1.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 65ms/step - accuracy: 0.5837 - loss: 1.1915 - val_accuracy: 0.5890 - val_loss: 1.1592 - learning_rate: 1.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 64ms/step - accuracy: 0.6875 - loss: 0.9276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:28:25.866465: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.4643 - val_accuracy: 0.5893 - val_loss: 1.1592 - learning_rate: 1.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.5837 - loss: 1.1865 - val_accuracy: 0.5828 - val_loss: 1.1785 - learning_rate: 1.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 58ms/step - accuracy: 0.5938 - loss: 1.2982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:29:29.141276: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.6498 - val_accuracy: 0.5833 - val_loss: 1.1786 - learning_rate: 1.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 65ms/step - accuracy: 0.5854 - loss: 1.1883 - val_accuracy: 0.5904 - val_loss: 1.1599 - learning_rate: 1.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 58ms/step - accuracy: 0.6562 - loss: 1.1623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:30:30.729968: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6562 - loss: 0.5818 - val_accuracy: 0.5900 - val_loss: 1.1606 - learning_rate: 1.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 64ms/step - accuracy: 0.5886 - loss: 1.1779 - val_accuracy: 0.5915 - val_loss: 1.1590 - learning_rate: 1.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 70ms/step - accuracy: 0.5000 - loss: 1.4994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:31:31.496298: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 0.7505 - val_accuracy: 0.5907 - val_loss: 1.1586 - learning_rate: 1.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5902 - loss: 1.1743\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 65ms/step - accuracy: 0.5902 - loss: 1.1743 - val_accuracy: 0.5843 - val_loss: 1.1793 - learning_rate: 1.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 64ms/step - accuracy: 0.4375 - loss: 1.3780"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:32:32.341953: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 0.6898 - val_accuracy: 0.5844 - val_loss: 1.1790 - learning_rate: 1.0000e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 68ms/step - accuracy: 0.5891 - loss: 1.1675 - val_accuracy: 0.5992 - val_loss: 1.1409 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 67ms/step - accuracy: 0.5312 - loss: 1.3958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:33:36.491856: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.6987 - val_accuracy: 0.5995 - val_loss: 1.1408 - learning_rate: 1.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 65ms/step - accuracy: 0.5950 - loss: 1.1614 - val_accuracy: 0.5979 - val_loss: 1.1420 - learning_rate: 1.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 1.2851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:34:38.176575: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 0.6433 - val_accuracy: 0.5978 - val_loss: 1.1420 - learning_rate: 1.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 66ms/step - accuracy: 0.5962 - loss: 1.1596 - val_accuracy: 0.6013 - val_loss: 1.1397 - learning_rate: 1.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 70ms/step - accuracy: 0.4688 - loss: 1.3270"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:35:40.873415: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.6642 - val_accuracy: 0.6013 - val_loss: 1.1397 - learning_rate: 1.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 63ms/step - accuracy: 0.5939 - loss: 1.1557 - val_accuracy: 0.5995 - val_loss: 1.1383 - learning_rate: 1.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 62ms/step - accuracy: 0.5938 - loss: 1.0727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:36:40.822166: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.5370 - val_accuracy: 0.6002 - val_loss: 1.1381 - learning_rate: 1.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 64ms/step - accuracy: 0.6012 - loss: 1.1515 - val_accuracy: 0.6009 - val_loss: 1.1362 - learning_rate: 1.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 60ms/step - accuracy: 0.4688 - loss: 1.2862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:37:41.632758: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.6438 - val_accuracy: 0.6004 - val_loss: 1.1362 - learning_rate: 1.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 65ms/step - accuracy: 0.5993 - loss: 1.1512 - val_accuracy: 0.6017 - val_loss: 1.1363 - learning_rate: 1.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 71ms/step - accuracy: 0.5625 - loss: 1.2779"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:38:43.555314: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.6397 - val_accuracy: 0.6021 - val_loss: 1.1361 - learning_rate: 1.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 68ms/step - accuracy: 0.5923 - loss: 1.1620 - val_accuracy: 0.5995 - val_loss: 1.1372 - learning_rate: 1.0000e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 105ms/step - accuracy: 0.5312 - loss: 1.3530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:39:48.175683: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.6773 - val_accuracy: 0.5997 - val_loss: 1.1371 - learning_rate: 1.0000e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.5868 - loss: 1.1703 - val_accuracy: 0.6016 - val_loss: 1.1343 - learning_rate: 1.0000e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 67ms/step - accuracy: 0.6562 - loss: 1.0908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:40:52.030702: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.5460 - val_accuracy: 0.6014 - val_loss: 1.1343 - learning_rate: 1.0000e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 65ms/step - accuracy: 0.5931 - loss: 1.1713 - val_accuracy: 0.6016 - val_loss: 1.1344 - learning_rate: 1.0000e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 78ms/step - accuracy: 0.5625 - loss: 1.3623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:41:54.563674: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.6819 - val_accuracy: 0.6016 - val_loss: 1.1344 - learning_rate: 1.0000e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 69ms/step - accuracy: 0.5962 - loss: 1.1600 - val_accuracy: 0.6014 - val_loss: 1.1351 - learning_rate: 1.0000e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 62ms/step - accuracy: 0.5625 - loss: 1.2685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:42:59.848311: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.6350 - val_accuracy: 0.6018 - val_loss: 1.1351 - learning_rate: 1.0000e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 66ms/step - accuracy: 0.5943 - loss: 1.1631 - val_accuracy: 0.5995 - val_loss: 1.1362 - learning_rate: 1.0000e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 66ms/step - accuracy: 0.3750 - loss: 1.3842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:44:02.166203: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 0.6929 - val_accuracy: 0.5999 - val_loss: 1.1363 - learning_rate: 1.0000e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 66ms/step - accuracy: 0.5976 - loss: 1.1532 - val_accuracy: 0.5991 - val_loss: 1.1376 - learning_rate: 1.0000e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 70ms/step - accuracy: 0.6562 - loss: 0.9031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:45:05.271587: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.4520 - val_accuracy: 0.5989 - val_loss: 1.1376 - learning_rate: 1.0000e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 63ms/step - accuracy: 0.5956 - loss: 1.1581 - val_accuracy: 0.5985 - val_loss: 1.1367 - learning_rate: 1.0000e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 60ms/step - accuracy: 0.5625 - loss: 1.1438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:46:05.798810: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 0.5726 - val_accuracy: 0.5984 - val_loss: 1.1368 - learning_rate: 1.0000e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5951 - loss: 1.1650\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 65ms/step - accuracy: 0.5951 - loss: 1.1650 - val_accuracy: 0.5985 - val_loss: 1.1359 - learning_rate: 1.0000e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 66ms/step - accuracy: 0.3750 - loss: 1.4120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:47:07.008721: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 0.7068 - val_accuracy: 0.5986 - val_loss: 1.1359 - learning_rate: 1.0000e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.5962 - loss: 1.1489 - val_accuracy: 0.5993 - val_loss: 1.1343 - learning_rate: 1.0000e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58s\u001b[0m 65ms/step - accuracy: 0.6562 - loss: 1.0831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:48:10.754670: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6562 - loss: 0.5422 - val_accuracy: 0.5993 - val_loss: 1.1343 - learning_rate: 1.0000e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.5933 - loss: 1.1559 - val_accuracy: 0.5989 - val_loss: 1.1352 - learning_rate: 1.0000e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 71ms/step - accuracy: 0.6562 - loss: 0.9881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:49:13.714048: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.4946 - val_accuracy: 0.5989 - val_loss: 1.1352 - learning_rate: 1.0000e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 65ms/step - accuracy: 0.5982 - loss: 1.1525 - val_accuracy: 0.6003 - val_loss: 1.1337 - learning_rate: 1.0000e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 61ms/step - accuracy: 0.5625 - loss: 1.2751"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:50:16.416895: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.6383 - val_accuracy: 0.5999 - val_loss: 1.1338 - learning_rate: 1.0000e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 66ms/step - accuracy: 0.5988 - loss: 1.1518 - val_accuracy: 0.5997 - val_loss: 1.1339 - learning_rate: 1.0000e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 68ms/step - accuracy: 0.5625 - loss: 1.0738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:51:19.253012: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.5375 - val_accuracy: 0.6000 - val_loss: 1.1340 - learning_rate: 1.0000e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 68ms/step - accuracy: 0.5940 - loss: 1.1599 - val_accuracy: 0.5992 - val_loss: 1.1345 - learning_rate: 1.0000e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:11\u001b[0m 80ms/step - accuracy: 0.5625 - loss: 1.4633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:52:23.840485: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.7325 - val_accuracy: 0.5991 - val_loss: 1.1346 - learning_rate: 1.0000e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 67ms/step - accuracy: 0.5940 - loss: 1.1618 - val_accuracy: 0.5991 - val_loss: 1.1340 - learning_rate: 1.0000e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m  1/897\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:04\u001b[0m 72ms/step - accuracy: 0.5312 - loss: 1.2600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 14:53:27.460592: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.6307 - val_accuracy: 0.5991 - val_loss: 1.1340 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "model.fit(data_generator.flow(xtrain, ytrain, batch_size), \n",
    "          steps_per_epoch=len(xtrain)//batch_size, \n",
    "          epochs=epochs, \n",
    "          verbose=1, \n",
    "          callbacks=callbacks, \n",
    "          validation_data=(xtest, ytest))\n",
    "model.save('mini_xception_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac71b919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/jd/0x5q_vls0_g80fd17j5cgvmw0000gn/T/tmpn575wcq6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/jd/0x5q_vls0_g80fd17j5cgvmw0000gn/T/tmpn575wcq6/assets\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_path = 'mini_xception_model.tflite'\n",
    "open(tflite_model_path, 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50f31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed3eabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the input image\n",
    "img = cv2.imread('dabke.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fc34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n"
     ]
    }
   ],
   "source": [
    "# Define the emotion labels\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "# Iterate over the detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    # Extract the face region from the image\n",
    "    face_roi = gray[y:y+h, x:x+w]\n",
    "    \n",
    "    # Preprocess the face region (e.g., resize, normalization)\n",
    "    face_roi = cv2.resize(face_roi, (48, 48))\n",
    "    face_roi = face_roi.astype('float32') / 255.0\n",
    "    face_roi = np.expand_dims(face_roi, axis=0)\n",
    "    face_roi = np.expand_dims(face_roi, axis=-1)\n",
    "    \n",
    "    # Use the loaded model to predict the emotion\n",
    "    emotion_prediction = model.predict(face_roi)\n",
    "    emotion_index = np.argmax(emotion_prediction)\n",
    "    emotion_label = emotion_labels[emotion_index]\n",
    "    \n",
    "    # Draw a rectangle around the face and display the emotion label\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    cv2.putText(img, emotion_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "# Display the image with emotion detection\n",
    "cv2.imshow('Emotion Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the emotion recognition model (using OpenCV's SVM implementation)\n",
    "emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "fishface = cv2.ml.FisherFaceRecognizer_create()\n",
    "fishface.read('mini_xception_model.h5')\n",
    "\n",
    "# Function to extract features from the face region\n",
    "def extract_features(gray, roi):\n",
    "    roi_gray = gray[roi[1]:roi[1]+roi[3], roi[0]:roi[0]+roi[2]]\n",
    "    roi_gray = cv2.resize(roi_gray, (48, 48))\n",
    "    roi_gray = roi_gray.flatten()\n",
    "    return roi_gray\n",
    "\n",
    "# Open the video capture or load an image\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for webcam or provide a video file path\n",
    "while True:\n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Iterate over the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract features from the face region\n",
    "        features = extract_features(gray, (x, y, w, h))\n",
    "\n",
    "        # Predict the emotion using the SVM model\n",
    "        predicted_emotion = fishface.predict(np.array([features]))[0]\n",
    "        emotion_label = emotions[predicted_emotion]\n",
    "\n",
    "        # Draw a rectangle around the face and display the emotion label\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, emotion_label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Emotion Detection', frame)\n",
    "\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c1857d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
